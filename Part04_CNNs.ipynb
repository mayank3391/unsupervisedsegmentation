{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "### Numpy\n",
    "import numpy as np\n",
    "\n",
    "### Skimage\n",
    "from skimage import segmentation\n",
    "\n",
    "### matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### PIL\n",
    "from PIL import Image\n",
    "\n",
    "### Pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Torch Imports\n",
    "import torch\n",
    "import torch.nn.init\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Display parameters\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (20, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag to check CUDA compatible GPU\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "nChannel = 100 # Number of conv filters/output channels\n",
    "maxIter = 50 # Number of iterations\n",
    "minLabels = 5 # Number of clusters\n",
    "lr = 0.1 # Learning rate\n",
    "nConv = 3 # Number of conv layers\n",
    "num_superpixels = 100000 # Number of superpixels\n",
    "compactness = 10 # Compactness of superpixels\n",
    "visualize = 0 # Visualization flag\n",
    "input_img = \"NAIP_minis/0_2400.tif\" # Input image\n",
    "\n",
    "mask_flag = 1 # For masking based on (k2) NAIP masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "class MyNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim):\n",
    "        \n",
    "        super(MyNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_dim, nChannel, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(nChannel)\n",
    "        self.conv2 = []\n",
    "        self.bn2 = []\n",
    "        \n",
    "        for i in range(nConv-1):\n",
    "            self.conv2.append(nn.Conv2d(nChannel, nChannel, kernel_size=3, stride=1, padding=1))\n",
    "            self.bn2.append(nn.BatchNorm2d(nChannel))\n",
    "            \n",
    "        self.conv3 = nn.Conv2d(nChannel, nChannel, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(nChannel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        \n",
    "        for i in range(nConv-1):\n",
    "            x = self.conv2[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = self.bn2[i](x)\n",
    "            \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 800, 3)\n"
     ]
    }
   ],
   "source": [
    "# load image\n",
    "im = Image.open(input_img)\n",
    "im = numpy.array(im)\n",
    "im = im[:, :, 1:4]\n",
    "print (im.shape)\n",
    "\n",
    "data = torch.from_numpy(np.array([im.transpose((2, 0, 1)).astype('float32')/255.]))\n",
    "\n",
    "if use_cuda:\n",
    "    data = data.cuda()\n",
    "    \n",
    "data = Variable(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slic\n",
    "labels = segmentation.slic(im, compactness=compactness, n_segments=num_superpixels, multichannel=True)\n",
    "labels = labels.reshape(im.shape[0]*im.shape[1])\n",
    "u_labels = np.unique(labels)\n",
    "l_inds = []\n",
    "\n",
    "for i in range(len(u_labels)):\n",
    "    l_inds.append(np.where(labels == u_labels[i])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 50 : 73 tensor(3.7100)\n",
      "1 / 50 : 74 tensor(3.5854)\n",
      "2 / 50 : 74 tensor(3.4221)\n",
      "3 / 50 : 72 tensor(3.2624)\n",
      "4 / 50 : 72 tensor(3.1062)\n",
      "5 / 50 : 68 tensor(2.9542)\n",
      "6 / 50 : 70 tensor(2.7905)\n",
      "7 / 50 : 68 tensor(2.6173)\n",
      "8 / 50 : 65 tensor(2.4415)\n",
      "9 / 50 : 62 tensor(2.2668)\n",
      "10 / 50 : 60 tensor(2.0920)\n",
      "11 / 50 : 55 tensor(1.9220)\n",
      "12 / 50 : 49 tensor(1.7620)\n",
      "13 / 50 : 45 tensor(1.6149)\n",
      "14 / 50 : 35 tensor(1.4773)\n",
      "15 / 50 : 32 tensor(1.3572)\n",
      "16 / 50 : 27 tensor(1.2512)\n",
      "17 / 50 : 26 tensor(1.1575)\n",
      "18 / 50 : 23 tensor(1.0732)\n",
      "19 / 50 : 19 tensor(0.9981)\n",
      "20 / 50 : 16 tensor(0.9315)\n",
      "21 / 50 : 16 tensor(0.8733)\n",
      "22 / 50 : 14 tensor(0.8241)\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "model = MyNet(data.size(1))\n",
    "\n",
    "if use_cuda:\n",
    "    \n",
    "    model.cuda()\n",
    "    \n",
    "    for i in range(nConv-1):\n",
    "        \n",
    "        model.conv2[i].cuda()\n",
    "        model.bn2[i].cuda()\n",
    "        \n",
    "model.train()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "label_colours = np.random.randint(255, size=(100,3))\n",
    "\n",
    "for batch_idx in range(maxIter):\n",
    "    \n",
    "    # forward prop\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)[0]\n",
    "    output = output.permute(1, 2, 0).contiguous().view(-1, nChannel)\n",
    "    ignore, target = torch.max(output, 1)\n",
    "    im_target = target.data.cpu().numpy()\n",
    "    nLabels = len(np.unique(im_target))\n",
    "    \n",
    "    if visualize:\n",
    "        \n",
    "        im_target_rgb = np.array([label_colours[c%100] for c in im_target])\n",
    "        im_target_rgb = im_target_rgb.reshape((im.shape[0], im.shape[1], 3)).astype(np.uint8)\n",
    "        # cv2.imshow(\"output\", im_target_rgb)\n",
    "        # cv2.waitKey(10)\n",
    "        # im_target_rgb = Image.fromarray(im_target_rgb)\n",
    "        \n",
    "        # if batch_idx%10 == 0:\n",
    "            # name = \"NAIP_trainoverCNN/\" + str(batch_idx) + \"_\" + input_img[11:-4] + \".jpg\"\n",
    "            # im_target_rgb.save(name)\n",
    "            \n",
    "    # superpixel refinement\n",
    "    for i in range(len(l_inds)):\n",
    "        \n",
    "        labels_per_sp = im_target[l_inds[i]]\n",
    "        u_labels_per_sp = np.unique(labels_per_sp)\n",
    "        hist = np.zeros(len(u_labels_per_sp))\n",
    "        \n",
    "        for j in range(len(hist)):\n",
    "            \n",
    "            hist[j] = len(np.where(labels_per_sp == u_labels_per_sp[j])[0])\n",
    "            \n",
    "        im_target[l_inds[i]] = u_labels_per_sp[np.argmax(hist)]\n",
    "        \n",
    "    target = torch.from_numpy(im_target)\n",
    "    \n",
    "    if use_cuda:\n",
    "        \n",
    "        target = target.cuda()\n",
    "        \n",
    "    target = Variable(target)\n",
    "    loss = loss_fn(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print (batch_idx, '/', maxIter, ':', nLabels, loss.data[0])\n",
    "    \n",
    "    if nLabels <= 10:\n",
    "        \n",
    "        im_target_rgb = np.array([label_colours[c] for c in im_target])\n",
    "        im_target_rgb = im_target_rgb.reshape((im.shape[0], im.shape[1], 3)).astype(np.uint8)\n",
    "        name = \"NAIP_trainCNN/\" + str(batch_idx) + \"_\" + input_img[11:-4] + \"_test.jpg\"\n",
    "        im_target_rgb = Image.fromarray(im_target_rgb)\n",
    "        im_target_rgb.save(name)\n",
    "    \n",
    "    if nLabels <= minLabels:\n",
    "        \n",
    "        print (\"nLabels\", nLabels, \"reached minLabels\", minLabels, \".\")\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = model(data)[0]\n",
    "print (output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.permute(1, 2, 0).contiguous().view(-1, nChannel)\n",
    "print (output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore, target = torch.max(output, 1)\n",
    "print (ignore.shape)\n",
    "print (target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_target = target.data.cpu().numpy()\n",
    "print (im_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = Counter(list(im_target.flatten()))\n",
    "lbl = lbl.most_common()\n",
    "lbl = [lbl[i][0] for i in range(len(lbl))]\n",
    "lbl = np.array(lbl)\n",
    "lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['green', 'blue', 'darkorange', 'deeppink', 'cyan', 'indigo', 'crimson', 'grey', 'white', 'lightsalmon', 'pink']\n",
    "clr_lst = ['3cb44b', '0082c8', 'FF8C00', 'FF1493', '46f0f0', '4B0082', 'e6194b', '808080', 'FFFFFF', 'FFA07A', 'fabebe']\n",
    "clr_lst = clr_lst[:len(lbl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert hex color representations to RGB values\n",
    "colors = []\n",
    "for index in range(len(lbl)):\n",
    "    rgb = list(int(clr_lst[index][i:i+2], 16) for i in (0, 2 ,4))\n",
    "    colors.append(rgb)\n",
    "    \n",
    "color = np.array(colors)\n",
    "print (color.shape)\n",
    "color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask\n",
    "im_target_rgb_org = np.array([color[np.where(lbl==c)[0][0]] for c in im_target])\n",
    "im_target_rgb = np.copy(im_target_rgb_org)\n",
    "\n",
    "maskName = input_img[11:-4] + \"_mask.npy\"\n",
    "maskPath = \"NAIP_masksnpy/\" + str(maskName)\n",
    "mask = np.load(maskPath)\n",
    "idx_mask = np.array(np.where(mask!=mask_flag)[0])\n",
    "im_target_rgb[idx_mask] = 0\n",
    "\n",
    "im_target_rgb = im_target_rgb.reshape((im.shape[0], im.shape[1], 3)).astype(np.uint8)\n",
    "im_target_rgb = Image.fromarray(im_target_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_color = defaultdict(int)\n",
    "for pixel in im_target_rgb.getdata():\n",
    "     by_color[pixel] += 1\n",
    "by_color\n",
    "\n",
    "s = [(k, by_color[k]) for k in sorted(by_color, key=by_color.get, reverse=True)]\n",
    "for k, v in s:\n",
    "    print (k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im_target_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
